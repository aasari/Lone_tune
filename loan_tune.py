# -*- coding: utf-8 -*-
"""Loan_tune

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/112iOTW2QvUQ2JUlL2YdPApmZNhp5UtHh
"""

from google.colab import files

upload = files.upload()

import io
import pandas as pd
df = pd.read_csv(io.BytesIO(upload['Loan.csv']))

# Commented out IPython magic to ensure Python compatibility.
#import packages
import pandas as pd
import numpy as np

#to plot within notebook
import matplotlib.pyplot as plt
# %matplotlib inline

#setting figure size
from matplotlib.pylab import rcParams
rcParams['figure.figsize'] = 20,10

#for normalizing data
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))

#read the file
#df = pd.read_csv('NSE-TATAGLOBAL(1).csv')

#print the head
df.head()

pd.isnull(df).sum()

df.Gender.value_counts()

df['Gender']  = df['Gender'].fillna('Male')

df.Married.value_counts()

df['Married']  = df['Married'].fillna('Yes')

df.Dependents.value_counts()

df['Dependents']  = df['Dependents'].fillna('0')

df.Self_Employed.value_counts()

df['Self_Employed']  = df['Self_Employed'].fillna('No')

df.LoanAmount.value_counts()

df['LoanAmount']  = df['LoanAmount'].fillna(df['LoanAmount'].mean())

df.Loan_Amount_Term.value_counts()

df['Loan_Amount_Term']  = df['Loan_Amount_Term'].fillna(df.Loan_Amount_Term.value_counts().idxmax())

df.Credit_History.value_counts()

df['Credit_History']  = df['Credit_History'].fillna(df.Credit_History.value_counts().idxmax())

df.isnull().sum()

df.Loan_status.value_counts()

df.info()

from  sklearn import preprocessing

label_encoder =  preprocessing.LabelEncoder()

df['Gender'] = label_encoder.fit_transform(df['Gender'])

df.head()

df['Married'] = label_encoder.fit_transform(df['Married'])
df['Self_Employed'] = label_encoder.fit_transform(df['Self_Employed'])
df['Property_Area'] = label_encoder.fit_transform(df['Property_Area'])

df['Education'] = label_encoder.fit_transform(df['Education'])

df['Dependents'] = label_encoder.fit_transform(df['Dependents'])

df['Loan_status'] = label_encoder.fit_transform(df['Loan_status'])

plt.title('Applicant_Income Distriution')
plt.xlabel('Loan ID')
plt.ylabel('Applicant_Income')
plt.scatter(df.Loan_ID,df.LoanAmount)
plt.show()

plt.boxplot(df['ApplicantIncome'])

df.describe()

Q1 = df_no_out.LoanAmount.quantile(0.25)
Q3 = df_no_out.LoanAmount.quantile(0.75)
Q1,Q3

IQR = Q3 - Q1
IQR

upper_limit = Q3 + 1.5*IQR
lower_limit = Q1 - 1.5*IQR 
upper_limit,  lower_limit

df_no_out  = df_no_out[(df_no_out.LoanAmount<upper_limit)  &  (df_no_out.LoanAmount>lower_limit)]

df_no_out.shape

plt.scatter(df_no_out.Loan_ID,df_no_out.LoanAmount)
plt.show()

df_no_out.shape

df_no_out = pd.DataFrame(df_no_out)
df_no_out = df_no_out.drop(['Loan_ID'],axis=1)

df_no_out.info()

from sklearn.model_selection import train_test_split

X_out = df_no_out[df_no_out.columns[:-1]]
Y_out = df_no_out[df_no_out.columns[-1]]

X_train,X_test,Y_train,Y_test =  train_test_split(X_out,Y_out, test_size = 0.20)

X_train_scale = ss.fit_transform(X_train)
X_test_scale  = ss.fit_transform(X_test)

model.fit(X_train_scale,Y_train)

y_pred = model.predict(X_test_scale)

y_pred

Y_test

model.score(X_test_scale,Y_test)

from sklearn.metrics import classification_report,confusion_matrix

print(classification_report(Y_test,y_pred))

confusion_matrix(Y_test,y_pred)

from sklearn.metrics import roc_curve, roc_auc_score

y_score1 = model.predict_proba(X_test_scale)
y_score2 = svc_model.predict_proba(X_test_scale)

fpr1, tpr1, thresh1 = roc_curve(Y_test, y_score1[:,1], pos_label=1)
fpr2, tpr2, thresh2 = roc_curve(Y_test, y_score2[:,1], pos_label=1)

random_probs = [0 for i in range(len(Y_test))]
p_fpr, p_tpr, _ = roc_curve(Y_test, random_probs, pos_label=1)

auc_score1 = roc_auc_score(Y_test, y_score1[:,1])
auc_score2 = roc_auc_score(Y_test, y_score2[:,1])

print(auc_score1, auc_score2)

import matplotlib.pyplot as plt
plt.style.use('seaborn')

# plot roc curves
plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')
plt.plot(fpr2, tpr2, linestyle='--',color='green', label='SVM')
plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')
# title
plt.title('ROC curve')
# x label
plt.xlabel('False Positive Rate')
# y label
plt.ylabel('True Positive rate')

plt.legend(loc='best')
plt.savefig('ROC',dpi=300)
plt.show();

from sklearn.preprocessing import MinMaxScaler

ss = MinMaxScaler()

df = pd.DataFrame(df)

df = df.drop(['Loan_ID'],axis=1)

df.info()

from sklearn.model_selection import train_test_split

df.head()

X  = df[df.columns[:-1]]
Y = df[df.columns[-1]]

X.head()

Y.head()

X.shape

Y.shape

X_train,X_test,Y_train,Y_test =  train_test_split(X,Y, test_size = 0.20)

X_train.shape,Y_train.shape

X_test.shape,Y_test.shape

X_train_scale = ss.fit_transform(X_train)

X_test_scale  = ss.fit_transform(X_test)

from sklearn.linear_model import LogisticRegression

model =  LogisticRegression()

model.fit(X_train_scale,Y_train)

y_pred = model.predict(X_test_scale)

model.score(X_test_scale,Y_test)

from sklearn.model_selection import KFold, RepeatedKFold
from sklearn.model_selection import cross_val_score

cv = KFold(n_splits=10, random_state=1, shuffle=True)
scores = cross_val_score(model, X_train_scale, Y_train, scoring='accuracy', cv=cv, n_jobs=-1)

cross_val_score(LogisticRegression(), X_train_scale, Y_train)

cross_val_score(SVC(), X_train_scale, Y_train)

cross_val_score(RandomForestClassifier(), X_train_scale, Y_train)

cross_val_score(XGBClassifier(), X_train_scale, Y_train)



from numpy import std
from numpy import mean
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

cv1 = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
scores1 = cross_val_score(model, X_train_scale, Y_train, scoring='accuracy', cv=cv1, n_jobs=-1)

print('Accuracy: %.3f (%.3f)' % (mean(scores1), std(scores1)))

from sklearn.svm import SVC

svc_model = SVC(probability=True)

svc_model.fit(X_train_scale,Y_train)

svc_pred = svc_model.predict(X_test_scale)

svc_model.score(X_test_scale,Y_test)

from sklearn import metrics

cm = metrics.confusion_matrix(Y_test,svc_pred)

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(criterion='entropy')

dt.fit(X_train_scale,Y_train)

dt_pred = dt.predict(X_test_scale)

dt.score(X_test_scale,Y_test)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=40,criterion='entropy')

rf.fit(X_train_scale,Y_train)

rf_pred = rf.predict(X_test_scale)

rf.score(X_test_scale,Y_test)

from sklearn.metrics import accuracy_score

acc = accuracy_score(Y_test,rf_pred)

acc

from xgboost import XGBClassifier

xg = XGBClassifier()

xg.fit(X_train_scale,Y_train)

xg_pred = xg.predict(X_test_scale)

xg.score(X_test_scale,Y_test)

from sklearn.ensemble import AdaBoostClassifier

cross_val_score(AdaBoostClassifier(), X_train_scale, Y_train)

